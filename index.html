<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="A unified framework that allows high-quality dynamic Gaussian Splatting from both defocused and motion-blurred monocular videos.">
  <meta name="keywords" content="Dynamic Gaussian Splatting, Deblurring">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Dynamic Gaussian Splatting from Defocused and Motion-blurred Monocular Videos</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon_new.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Dynamic Gaussian Splatting from Defocused and Motion-blurred Monocular Videos</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">Xuankai Zhang<sup>1</sup>,</span>
            <span class="author-block">Junjin Xiao<sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=qH0rU44AAAAJ&hl=en">Qing Zhang</a><sup>1,2<sup>*</sup></sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>School of Computer Science and Engineering, Sun Yat-sen University, China </span>
            <span class="author-block"><sup>2</sup>Key Laboratory of Machine Intelligence and Advanced Computing, Ministry of Education, China</span>
            <span class="author-block"><sup>*</sup>Corresponding author</span>
          </div>

          <div class="is-size-5 has-text-weight-bold" style="text-align: center">
            NeurIPS 2025
          </div>

          <div style="height: 1.25em"></div>
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- arXiv Link. -->
              <span class="link-block">
                <a href="https://dydeblur.github.io/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>

              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://dydeblur.github.io/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- NOTE Teaser -->
<section class="section">
  <div style="text-align: center;"></p>
    <img id="method" width="45%" src="static/images/teaser.svg"> 
    </p>
       Our method allows to synthesize high-quality sharp novel views for videos with defocus blur (top) and motion blur (bottom). 
    </p>
 </div>    
</section>

<!-- Semantic Map to LiDAR -->
<section class="section"  style="margin-top: 0; padding-top: 50px;">
  <h2 class="title is-4" style="text-align: center;">More Results (D2RF Dataset)</h2>
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width" style="text-align: center">
      </div>
    </div>
  </div>
    <div class="hero-body">
    <div class="container">
      <div id="results-sem2lidar" class="carousel results-carousel">
      <div class="column is-full-width">
        <video poster="" id="ade" autoplay controls muted loop playsinline height="10%">
          <source src="./static/videos/Camp.mp4"
                  type="video/mp4">
        </video>
      </div>
      <div class="column is-full-width">
        <video poster="" id="ade" autoplay controls muted loop playsinline height="10%">
          <source src="./static/videos/Car.mp4"
                  type="video/mp4">
        </video>
      </div>
      <div class="column is-full-width">
        <video poster="" id="ade" autoplay controls muted loop playsinline height="10%">
          <source src="./static/videos/Dining1.mp4"
                  type="video/mp4">
        </video>
      </div>
      <div class="column is-full-width">
        <video poster="" id="ade" autoplay controls muted loop playsinline height="10%">
          <source src="./static/videos/Dock.mp4"
                  type="video/mp4">
        </video>
      </div>
      <div class="column is-full-width">
        <video poster="" id="ade" autoplay controls muted loop playsinline height="10%">
          <source src="./static/videos/Gate.mp4"
                  type="video/mp4">
        </video>
      </div>
        </div>
    </div>

  </div>
</section>

<!-- NOTE D2RF Videos -->
<section class="hero is-light is-small">
  <h2 class="title is-3 has-text-centered">More Results (D2RF Dataset)</h2>
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel" data-items="1">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/Camp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/Car.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/Dining1.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/Dock.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/Gate.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- NOTE DyBluRF Videos -->
<section class="hero is-light is-small">
  <h2 class="title is-3 has-text-centered">More Results (DyBluRF Dataset)</h2>
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel" data-items="1">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/seesaw.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/skating.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/street.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/third.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/women.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            This paper presents a unified framework that allows high-quality dynamic Gaussian
            Splatting from both defocused and motion-blurred monocular videos. Due to the
            significant difference between the formation processes of defocus blur and motion
            blur, existing methods are tailored for either one of them, lacking the ability to
            simultaneously deal with both of them. Although the two can be jointly modeled
            as blur kernel-based convolution, the inherent difficulty in estimating accurate blur
            kernels greatly limits the progress in this direction. In this work, we go a step
            further towards this direction. Particularly, we propose to estimate per-pixel reliable
            blur kernels using a blur prediction network that exploits blur-related scene and
            camera information and is subject to a blur-aware sparsity constraint. Besides, we
            introduce a dynamic Gaussian densification strategy to mitigate the lack of Gaus
            sians for incomplete regions, and boost the performance of novel view synthesis by
            incorporating unseen view information to constrain scene optimization. Extensive
            experiments show that our method outperforms the state-of-the-art methods in
            generating photorealistic novel view synthesis from defocused and motion-blurred
            monocular videos. Our code and trained model will be made publicly available.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->


    <!-- Method. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
        <h2 class="title is-3"> Method </h2>
      </div>
    </div>
    <div style="text-align: center;"></p>
      <img id="method" width="100%" src="static/images/overview.png"> 
      </p>
        Overview of our method.
      </p>
    <!-- Method. -->
    
  </div>    

  </div>
</section>


<!-- Concurrent Work. -->
<section class="section" id="Related work">
  <div class="container is-max-desktop content">
    <h2 class="title is-3">Related links</h2>
    We recognize that a few concurrent works address similar problems to ours. We encourage you to check them out: <br>
    <li><a href="https://shape-of-motion.github.io/">Shape of Motion: 4D Reconstruction from a Single Video</a></li>
    <li><a href="https://deblur4dgs.github.io/">Deblur4DGS: 4D Gaussian Splatting from Blurry Monocular Video</a></li>
    <li><a href="https://huiqiang-sun.github.io/dyblurf/">DyBluRF: Dynamic Neural Radiance Fields from Blurry Monocular Video</a></li> 
    <li><a href="https://github.com/xianrui-luo/D2RF">Dynamic Neural Radiance Field From Defocused Monocular Video</a></li>
    <li><a href="https://ingra14m.github.io/Deformable-Gaussians/">Deformable 3D Gaussians for High-Fidelity Monocular Dynamic Scene Reconstruction</a></li>
  </div>
</section>
<!--/ Concurrent Work. -->

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{dydeblur,
  author    = {Zhang, Xuankai and Xiao, Junjin and Zhang, Qing},
  title     = {Dynamic Gaussian Splatting from Defocused and Motion-blurred Monocular Videos},
  journal   = {NeurIPS},
  year      = {2025},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
